{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # Only use this if using iPython\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline # Only use this if using iPython\n",
    "\n",
    "image_index = 7777 # You may select anything up to 60,000\n",
    "\n",
    "print(y_train[image_index]) # The label is 8\n",
    "\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "\n",
    "x_train /= 255\n",
    "\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=150)\n",
    "\n",
    "print(y_train[0])\n",
    "print(x_train[0])\n",
    "\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asojasingarayar\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asojasingarayar\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "# Creating a Sequential Model and adding the layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asojasingarayar\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.2031 - acc: 0.9387\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0816 - acc: 0.9750\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0571 - acc: 0.9822\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.0434 - acc: 0.9857\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0340 - acc: 0.9891\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0287 - acc: 0.9902\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0244 - acc: 0.9920\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0230 - acc: 0.9922\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0200 - acc: 0.9933:\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0157 - acc: 0.9947\n",
      "10000/10000 [==============================] - 7s 700us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0824029982236083, 0.9817]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x_train,y=y_train, epochs=10)\n",
    "\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0e317907fc7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_rows' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index =7777\n",
    "\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "\n",
    "pred = model.predict(x_test[image_index].reshape(1, img_rows, img_cols, 1))\n",
    "\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
